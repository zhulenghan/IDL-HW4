{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ytyXW-7Q6o"
      },
      "source": [
        "# Setup\n",
        "-  Follow the setup instructions based on your preferred environment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJDFDo87Q6s"
      },
      "source": [
        "## Local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One of our key goals in designing this assignment is to allow you to complete most of the preliminary implementation work locally.  \n",
        "We highly recommend that you **pass all tests locally** using the provided `hw4_data_subset` before moving to a GPU runtime.  \n",
        "To do this, simply:\n",
        "\n",
        "### Create a new conda environment\n",
        "```bash\n",
        "# Be sure to deactivate any active environments first\n",
        "conda create -n hw4 python=3.12.4\n",
        "```\n",
        "\n",
        "### Activate the conda environment\n",
        "```bash\n",
        "conda activate hw4\n",
        "```\n",
        "\n",
        "### Install the dependencies using the provided `requirements.txt`\n",
        "```bash\n",
        "pip install --no-cache-dir --ignore-installed -r requirements.txt\n",
        "```\n",
        "\n",
        "### Ensure that your notebook is in the same working directory as the `Handout`\n",
        "This can be achieved by:\n",
        "1. Physically moving the notebook into the handout directory.\n",
        "2. Changing the notebook‚Äôs current working directory to the handout directory using the os.chdir() function.\n",
        "\n",
        "### Open the notebook and select the newly created environment from the kernel selector.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îú‚îÄ‚îÄ hw4lib/\n",
        "‚îú‚îÄ‚îÄ mytorch/\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îî‚îÄ‚îÄ hw4_data_subset/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tub92oPW7Q6t"
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5qfxCxq7l-f"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0wRO-k-7Q6u"
      },
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"your_username_here\"\n",
        "REPO_NAME       = \"your_repo_name_here\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmxMiKjIYv2_"
      },
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfOQStjw7Q6w"
      },
      "source": [
        "### Step 2: Install Dependencies\n",
        "- `NOTE`: Your runtime will be restarted to ensure all dependencies are updated.\n",
        "- `NOTE`: You will see a runtime crashed message, this was intentionally done. Simply move on to the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "maupv9q17Q6w"
      },
      "source": [
        "%pip install --no-deps -r IDL-HW4/requirements.txt\n",
        "import os\n",
        "os.kill(os.getpid(), 9) # NOTE: This will restart the your colab Python runtime (required)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yj32DflNHuI"
      },
      "source": [
        "### Step 3: Obtain Data\n",
        "\n",
        "- `NOTE`: This process will automatically download and unzip data for both `HW4P1` and `HW4P2`.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeP-XgwYA_M3"
      },
      "source": [
        "!curl -L -o /content/s25-hw4-data.zip https://www.kaggle.com/api/v1/datasets/download/cmu11785/s25-hw4-data\n",
        "!unzip -q -o /content/s25-hw4-data.zip -d /content/hw4_data\n",
        "!rm -rf /content/s25-hw4-data.zip\n",
        "!du -h --max-depth=2 /content/hw4_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2YwJ0hy7Q6x"
      },
      "source": [
        "### Step 4: Move to Handout Directory\n",
        "You must be within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îú‚îÄ‚îÄ hw4lib/\n",
        "‚îú‚îÄ‚îÄ mytorch/\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îî‚îÄ‚îÄ hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzYdDIxw7Q6x"
      },
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While it is possible to run the notebook on Kaggle, we would recommend against it. This assignment is more resource intensive and may run slower on Kaggle. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"your_username_here\"\n",
        "REPO_NAME       = \"your_repo_name_here\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Install Dependencies\n",
        "- Simply set the `Environment` setting in the notebook to `Always use latest environment`. No need to install anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Obtain Data\n",
        "\n",
        "#### ‚ö†Ô∏è Important: Kaggle Users  \n",
        "If you are using Kaggle, **do not manually download the data!** The dataset is large and may exceed your available disk space. Instead, follow these steps to add the dataset directly to your notebook:\n",
        "\n",
        "1. Open your **Kaggle Notebook**.  \n",
        "2. Navigate to **Notebook ‚Üí Input**.  \n",
        "3. Click **Add Input**.  \n",
        "4. In the search bar, paste the following URL:  \n",
        "   üëâ [https://www.kaggle.com/datasets/cmu11785/s25-hw4-data](https://www.kaggle.com/datasets/cmu11785/s25-hw4-data)  \n",
        "5. Click the **‚ûï (plus sign)** to add the dataset to your notebook.  \n",
        "\n",
        "#### üìå Note:  \n",
        "This process will automatically download and unzip data for both `HW4P1` and `HW4P2`.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Move to Handout Directory\n",
        "You must be within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îú‚îÄ‚îÄ hw4lib/\n",
        "‚îú‚îÄ‚îÄ mytorch/\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îî‚îÄ‚îÄ hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQG51p6e7Q6x"
      },
      "source": [
        "## PSC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches.\n",
        "- If you use Remote - SSH to connect to Bridges2, you can upload the handout to your project directory and work from there.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"your_username_here\"\n",
        "REPO_NAME       = \"your_repo_name_here\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM4OZo_G7Q6x"
      },
      "source": [
        "### Step 2: Setting Up Your Environment on Bridges2\n",
        "\n",
        "For this homework, we are providing a shared Conda environment for the entire class. Follow these steps to set up the environment and start a Jupyter notebook on Bridges2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. SSH into Bridges2\n",
        "```bash\n",
        "ssh username@bridges2.psc.edu\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Navigate to your Project Directory\n",
        "```bash\n",
        "cd $PROJECT\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Load the Anaconda Module\n",
        "```bash\n",
        "module load anaconda3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Activate the provided HW4 Environment\n",
        "```bash\n",
        "conda deactivate # First, deactivate any existing Conda environment\n",
        "conda activate /jet/home/psamal/hw_envs/idl_hw4\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Request a Compute Node\n",
        "```bash\n",
        "interact -p GPU-shared --gres=gpu:v100-32:1 -t 8:00:00\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Re-activate Environment\n",
        "If your Conda environment was deactivated due to node allocation:\n",
        "```bash\n",
        "conda deactivate # First, deactivate any existing Conda environment\n",
        "conda activate /jet/home/psamal/hw_envs/idl_hw4\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Start Jupyter Notebook\n",
        "Launch Jupyter Notebook:\n",
        "```bash\n",
        "jupyter notebook --no-browser --ip=0.0.0.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### 8. Connect to Jupyter Server\n",
        "\n",
        "You can now use your prefered way of connecting to the Jupyter Server. Your options should be covered in the docs linked in post 558 @ piazza.\n",
        "\n",
        "The following is my preferred way of connecting to the Jupyter Server:\n",
        "\n",
        "##### 8.1 Connect in VSCode\n",
        "I prefer uploading the notebook to PSC Bridges2 storage ($PROJECT directory) and then connecting to the Jupyter Server from there.\n",
        "1. Use Remote - SSH to connect to Bridges2 and navigate to your project directory.\n",
        "2. Upload the notebook to the project directory.\n",
        "3. Open the notebook in VSCode.\n",
        "4. Go to **Kernel** ‚Üí **Select Another Kernel** ‚Üí **Existing Jupyter Server**\n",
        "5. Enter the URL of the Jupyter Server:```http://{hostname}:{port}/tree?token={token}```\n",
        "   - eg: `http://v011.ib.bridges2.psc.edu:8888/tree?token=e4b302434e68990f28bc2b4ae8d216eb87eecb7090526249` \n",
        "\n",
        "> **Note**: Replace `{hostname}`, `{port}` and `{token}` with your actual values from the Jupyter output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Get Data\n",
        "- `NOTE`: This will download and unzip data for both `HW4P1` and `HW4P2`\n",
        "- `NOTE`: We are using `$LOCAL`: the scratch storage on local disk on the node running a job to store out data. \n",
        "  - Disk accesses are much faster than what you would get from `$PROJECT` storage\n",
        "  - `IT IS NOT PERSISTENT`\n",
        "- `NOTE`: Make sure you have completed the previous steps before running this cell.\n",
        "- Read more about it PSC File Spaces [here](https://www.psc.edu/resources/bridges-2/user-guide#file-spaces)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!curl -L -o $LOCAL/s25-hw4-data.zip https://www.kaggle.com/api/v1/datasets/download/cmu11785/s25-hw4-data\n",
        "!unzip -q -o $LOCAL/s25-hw4-data.zip -d $LOCAL/hw4_data\n",
        "!rm -rf $LOCAL/s25-hw4-data.zip\\\n",
        "!du -h --max-depth=2 $LOCAL/hw4_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Move to Handout Directory\n",
        "Depending on the way you are running your notebook, you may or may not need to run this cell. As long as you are within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îú‚îÄ‚îÄ hw4lib/\n",
        "‚îú‚îÄ‚îÄ mytorch/\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îî‚îÄ‚îÄ hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Move to the handout directory if you are not there already\n",
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhPm0t5d7Q6z"
      },
      "source": [
        "# Imports\n",
        "\n",
        "- If your setup was done correctly, you should be able to run the following cell without any issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YAJF1-E87Q6z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from hw4lib.data import (\n",
        "    H4Tokenizer,\n",
        "    LMDataset,\n",
        "    verify_dataloader\n",
        ")\n",
        "from hw4lib.model import (\n",
        "    CausalMask,\n",
        "    PadMask,\n",
        "    PositionalEncoding,\n",
        "    DecoderOnlyTransformer\n",
        ")\n",
        "from hw4lib.utils import (\n",
        "    create_optimizer,\n",
        "    create_scheduler,\n",
        "    plot_lr_schedule\n",
        ")\n",
        "from hw4lib.trainers import (\n",
        "    LMTrainer,\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "import gc\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "import os\n",
        "import json\n",
        "import tarfile\n",
        "import shutil\n",
        "import wandb\n",
        "import yaml\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q4Ccp-M7Q60"
      },
      "source": [
        "# Implementations\n",
        "\n",
        "- `NOTE`: All of these implementations have detailed specification, implementation details, and hints in their respective source files. Make sure to read all of them in their entirety to understand the implementation details!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vqefJri7Q60"
      },
      "source": [
        "## MyTorch Implementations\n",
        "- Modify your `Linear` implementation from HW1P1 to support arbitrary number of dimensions in `mytorch/nn/linear.py`.\n",
        "- Modify your `Softmax` implementation from HW1P1 to support arbitrary number of dimensions in `mytorch/nn/activation.py`.\n",
        "- Implement the `ScaledDotProductAttention` class in `mytorch/nn/scaled_dot_product_attention.py`.\n",
        "- Implement the `MultiHeadAttention` class in `mytorch/nn/multi_head_attention.py`.\n",
        "- Run the cell below to check your implementations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hxzUzzW7Q60"
      },
      "source": [
        "!python -m tests.test_mytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8hb5VAN7Q60"
      },
      "source": [
        "## Dataset Implementation\n",
        "- Familiarize yourself with the `tokenize`, `encode`, and `decode` methods of the `H4Tokenizer` class in `hw4lib/data/tokenizer.py`. You will need to make use of these methods in both `HW4P1` and `HW4P2` both in the dataset implementations and during decoding.\n",
        "- Implement the `LMDataset` class in `hw4lib/data/lm_dataset.py`.\n",
        "    - You will have to implement parts of `__init__` and completely implement the `__len__`, `__getitem__` and `collate_fn` methods.\n",
        "- Run the cell below to check your implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1oCYvlJ7Q60"
      },
      "source": [
        "!python -m tests.test_dataset_lm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6R08H787Q60"
      },
      "source": [
        "## Model Implementations\n",
        "#### Overview:\n",
        "- Implement the `CausalMask` and `PadMask` functions in `hw4lib/modules/masks.py` to handle masking.\n",
        "- Implement the `PositionalEncoding` class in `hw4lib/model/positional_encoding.py` to handle positional encoding.\n",
        "- Implement the Transformer Sublayers: `SelfAttentionLayer` and `FeedForwardLayer` classes in `hw4lib/model/sublayers.py`.\n",
        "- Implement the Transformer Layer: `SelfAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py`.\n",
        "- Implement the `DecoderOnlyTransformer` class in `hw4lib/model/transformers.py`.\n",
        "- Run the cells below to check your implementation.\n",
        "- `NOTE`: Besides the `DecoderOnlyTransformer` (P1 mandatory, P2 optional), you will use all of the above implementations in both `HW4P1` and `HW4P2`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6m-85zB7Q61"
      },
      "source": [
        "### Masks\n",
        "- Implement the `PadMask` and `CausalMask` functions in `hw4lib/modules/masks.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of these masks in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di88pr8J7Q61"
      },
      "source": [
        "#### Causal Mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAHwBO7m7Q61"
      },
      "source": [
        "!python -m tests.test_mask_causal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCPEtI8X7Q61"
      },
      "source": [
        "#### Padding Mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiZusS-H7Q62"
      },
      "source": [
        "!python -m tests.test_mask_padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ZeV5XM7Q62"
      },
      "source": [
        "#### Optional: Visualize your Masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UqY1xD_7Q62"
      },
      "source": [
        "# Dummy data\n",
        "_d_model   = 64\n",
        "_x         = torch.zeros(4, 20, _d_model)\n",
        "_x_len     = torch.tensor([5, 15, 10, 20])\n",
        "_x_causal  = CausalMask(_x)\n",
        "_x_padding = PadMask(_x, _x_len)\n",
        "\n",
        "# Create figure with two subplots side by side\n",
        "fig, mask_axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot masks\n",
        "masks_and_titles = [\n",
        "    (_x_padding, \"Padding Mask\"),\n",
        "    (_x_causal, \"Causal Mask\")\n",
        "]\n",
        "\n",
        "# Plot each mask\n",
        "images = []\n",
        "for i, (mask, title) in enumerate(masks_and_titles):\n",
        "    im = mask_axs[i].imshow(mask, cmap=\"gray\", aspect='auto')\n",
        "    mask_axs[i].set_title(title, fontsize=8)\n",
        "    images.append(im)\n",
        "\n",
        "# Add colorbar at the bottom\n",
        "fig.subplots_adjust(bottom=0.2)  # Make space for colorbar\n",
        "cbar_ax = fig.add_axes([0.15, 0.1, 0.7, 0.02])  # [left, bottom, width, height]\n",
        "cbar = plt.colorbar(images[0], cax=cbar_ax, orientation='horizontal')\n",
        "cbar.ax.set_xlabel('Mask Values', labelpad=5, fontsize=8)\n",
        "cbar.set_ticks([0, 1])\n",
        "cbar.set_ticklabels(['Attend (0)', 'Ignore/Mask (1)'])\n",
        "cbar.ax.tick_params(labelsize=6)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkN0B1H7Q63"
      },
      "source": [
        "### Positional Encoding\n",
        "- Implement the `PositionalEncoding` class in `hw4lib/model/positional_encoding.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of this positional encoding in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTO-EMdY7Q63"
      },
      "source": [
        "!python -m tests.test_positional_encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehZGbq5G7Q64"
      },
      "source": [
        "#### Optional: Visualize your Positional Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cgKYbz47Q64"
      },
      "source": [
        "# Create sample positional encoding\n",
        "d_model = 64\n",
        "max_len = 100\n",
        "pos_encoding = PositionalEncoding(d_model=d_model, max_len=max_len)\n",
        "pe = pos_encoding.pe.squeeze(0).numpy()  # Remove batch dimension and convert to numpy\n",
        "\n",
        "# Create figure with two subplots side by side\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot 1: Positional encoding matrix\n",
        "im = ax1.imshow(pe, aspect='auto', cmap='RdBu',\n",
        "                extent=[0, d_model, max_len, 0])  # Flip y-axis to show position top-to-bottom\n",
        "plt.colorbar(im, ax=ax1, label='Encoding Value')\n",
        "ax1.set_xlabel('Dimension')\n",
        "ax1.set_ylabel('Position')\n",
        "ax1.set_title('Positional Encoding Matrix')\n",
        "ax1.grid(False)\n",
        "\n",
        "# Plot 2: Sinusoidal patterns\n",
        "dimensions = [0, 15, 31, 47, 63]  # Plot first few dimensions\n",
        "for dim in dimensions:\n",
        "    ax2.plot(pe[:, dim], label=f'dim {dim}')\n",
        "ax2.set_xlabel('Position')\n",
        "ax2.set_ylabel('Encoding Value')\n",
        "ax2.set_title('Sinusoidal Patterns for Different Dimensions')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSAUWGco7Q64"
      },
      "source": [
        "### Transformer Sublayers\n",
        "- Implement the Transformer Sublayers: `SelfAttentionLayer`, and `FeedForwardLayer` classes in `hw4lib/model/sublayers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of all of these sublayers in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4auGdGYy7Q64"
      },
      "source": [
        "!python -m tests.test_sublayer_selfattention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIy1d8757Q64"
      },
      "source": [
        "!python -m tests.test_sublayer_feedforward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfGn7MqL7Q65"
      },
      "source": [
        "### Transformer Self-Attention Decoder Layer\n",
        "- Implement the Transformer Layer: `SelfAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of this sublayer in `HW4P2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8p-8Uff7Q65"
      },
      "source": [
        "!python -m tests.test_decoderlayer_selfattention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0NW07hn7Q65"
      },
      "source": [
        "### Decoder-Only Transformer\n",
        "\n",
        "- Implement the `DecoderOnlyTransformer` class in `hw4lib/model/transformers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of in `HW4P1` and optionally `HW4P2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z1SU9b97Q65"
      },
      "source": [
        "!python -m tests.test_transformer_decoder_only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSGdoo9J7Q65"
      },
      "source": [
        "## Decoding Implementation\n",
        "- Implement the `generate_greedy` method of the `SequenceGenerator` class in `hw4lib/decoding/sequence_generator.py`.\n",
        "- Run the cell below to check your implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks5wXPYS7Q65"
      },
      "source": [
        "!python -m tests.test_decoding --mode greedy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainer Implementation\n",
        "You will have to do some minor in-filling for the `LMTrainer` class in `hw4lib/trainers/lm_trainer.py` before you can use it.\n",
        "- Fill in the `TODO`s in the `__init__`.\n",
        "- Fill in the `TODO`s in the `_train_epoch`.\n",
        "- Fill in the `TODO`s in the `_validate_epoch`.\n",
        "- Fill in the `TODO`s in the `generate` method.\n",
        "- Fill in the `TODO`s in the `train` method.\n",
        "\n",
        "`WARNING`: There are no test's for this. Implement carefully!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2-j-cKa7Q65"
      },
      "source": [
        "# Experiments\n",
        "From this point onwards you may want to switch to a `GPU` runtime. \n",
        "- `OBJECTIVE`: You must achieve a per-character perplexity ‚â§ 3.5 in order to get points for Task 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV2GWmKd7Q65"
      },
      "source": [
        "## Config\n",
        "- You can use the `config.yaml` file to set your config for your ablation study.\n",
        "\n",
        "---\n",
        "### Notes:\n",
        "\n",
        "- Set `tokenization: token_type:` to specify your desired tokenization strategy\n",
        "- You will need to set the root path to your `hw4p1_data` folder in `data: root:`. This will depend on your setup. For eg. if you are following out setup instruction:\n",
        "  - `PSC`: `\"/local/hw4_data/hw4p1_data\"`\n",
        "  - `Colab:`: `\"/content/hw4_data/hw4p1_data\"`\n",
        "  - `Kaggle:`: `\"/kaggle/input/s25-hw4-data/hw4p1_data\"`\n",
        "- There's extra configurations in the `optimizer` section which will only be relevant if you decide to use the `create_optimizer` function we've provided in `hw4lib/utils/create_optimizer.py`.\n",
        "- `BE CAREFUL` while setting numeric values. Eg. `1e-4` will get serialized to a `str` while `1.0e-4` gets serialized to float. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XLChmBx67Q65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting config_lm.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config_lm.yaml\n",
        "\n",
        "Name                      : \"lenghanz\"\n",
        "\n",
        "###### Tokenization ------------------------------------------------------------\n",
        "tokenization:\n",
        "  token_type                : \"10k\"       # [char, 1k, 5k, 10k]\n",
        "  token_map :\n",
        "      'char': 'hw4lib/data/tokenizer_jsons/tokenizer_char.json'\n",
        "      '1k'  : 'hw4lib/data/tokenizer_jsons/tokenizer_1000.json'\n",
        "      '5k'  : 'hw4lib/data/tokenizer_jsons/tokenizer_5000.json'\n",
        "      '10k' : 'hw4lib/data/tokenizer_jsons/tokenizer_10000.json'\n",
        "\n",
        "###### Dataset -----------------------------------------------------------------\n",
        "data:                    # Currently setup for Colab assuming out setup\n",
        "  root                 : \"hw4_data/hw4p1_data\"  # TODO: Set the root path of your data\n",
        "  train_partition      : \"train\"  # train\n",
        "  val_partition        : \"val\"    # val\n",
        "  test_partition       : \"test\"   # test\n",
        "  subset               : 1.0      # Load a subset of the data (for debugging, testing, etc\n",
        "  batch_size           : 1024      #\n",
        "  NUM_WORKERS          : 32        # Set to 0 for CPU\n",
        "\n",
        "###### Network Specs -------------------------------------------------------------\n",
        "model: # Decoder-Only Language Model (HW4P1)\n",
        "  d_model                   : 384\n",
        "  d_ff                      : 1536\n",
        "  num_layers                : 4\n",
        "  num_heads                 : 8\n",
        "  dropout                   : 0.1\n",
        "  layer_drop_rate           : 0.1\n",
        "  weight_tying              : True\n",
        "\n",
        "###### Common Training Parameters ------------------------------------------------\n",
        "training:\n",
        "  use_wandb                   : True   # Toggle wandb logging\n",
        "  wandb_run_id                : \"none\" # \"none\" or \"run_id\"\n",
        "  resume                      : False  # Resume an existing run (run_id != 'none')\n",
        "  epochs                      : 60\n",
        "  gradient_accumulation_steps : 1\n",
        "  wandb_project               : \"HW4P1\" # wandb project to log to\n",
        "\n",
        "###### Loss ----------------------------------------------------------------------\n",
        "loss: # Just good ol' CrossEntropy\n",
        "  label_smoothing: 0.1\n",
        "\n",
        "###### Optimizer -----------------------------------------------------------------\n",
        "optimizer:\n",
        "  name: \"adamw\" # Options: sgd, adam, adamw\n",
        "  lr: 5.0e-4   # Base learning rate\n",
        "\n",
        "  # Common parameters\n",
        "  weight_decay: 0.0001\n",
        "\n",
        "  # Parameter groups\n",
        "  param_groups:\n",
        "    - name: self_attn\n",
        "      patterns: []  # Will match all parameters containing keywords set their learning rate to 0.0001\n",
        "      lr: 0.0001    # LR for self_attn\n",
        "      layer_decay:\n",
        "        enabled: False\n",
        "        decay_rate: 0.8\n",
        "\n",
        "    - name: ffn\n",
        "      patterns: [] # Will match all parameters containing \"ffn\" and set their learning rate to 0.0001\n",
        "      lr: 0.0001   # LR for ffn\n",
        "      layer_decay:\n",
        "        enabled: False\n",
        "        decay_rate: 0.8\n",
        "\n",
        "  # Layer-wise learning rates\n",
        "  layer_decay:\n",
        "    enabled: False\n",
        "    decay_rate: 0.75\n",
        "\n",
        "  # SGD specific parameters\n",
        "  sgd:\n",
        "    momentum: 0.9\n",
        "    nesterov: True\n",
        "    dampening: 0\n",
        "\n",
        "  # Adam specific parameters\n",
        "  adam:\n",
        "    betas: [0.9, 0.999]\n",
        "    eps: 1.0e-8\n",
        "    amsgrad: False\n",
        "\n",
        "  # AdamW specific parameters\n",
        "  adamw:\n",
        "    betas: [0.9, 0.999]\n",
        "    eps: 1.0e-8\n",
        "    amsgrad: False\n",
        "\n",
        "###### Scheduler -----------------------------------------------------------------\n",
        "scheduler:\n",
        "  name: \"cosine\"  # Options: reduce_lr, cosine, cosine_warm\n",
        "\n",
        "  # ReduceLROnPlateau specific parameters\n",
        "  reduce_lr:\n",
        "    mode: \"min\"  # Options: min, max\n",
        "    factor: 0.1  # Factor to reduce learning rate by\n",
        "    patience: 10  # Number of epochs with no improvement after which LR will be reduced\n",
        "    threshold: 0.0001  # Threshold for measuring the new optimum\n",
        "    threshold_mode: \"rel\"  # Options: rel, abs\n",
        "    cooldown: 0  # Number of epochs to wait before resuming normal operation\n",
        "    min_lr: 0.0000001  # Minimum learning rate\n",
        "    eps: 1.0e-8  # Minimal decay applied to lr\n",
        "\n",
        "  # CosineAnnealingLR specific parameters\n",
        "  cosine:\n",
        "    T_max: 55  # Maximum number of iterations\n",
        "    eta_min: 1.0e-8  # Minimum learning rate\n",
        "    last_epoch: -1\n",
        "\n",
        "  # CosineAnnealingWarmRestarts specific parameters\n",
        "  cosine_warm:\n",
        "    T_0: 4  # Number of iterations for the first restart\n",
        "    T_mult: 4  # Factor increasing T_i after each restart\n",
        "    eta_min: 0.0000001  # Minimum learning rate\n",
        "    last_epoch: -1\n",
        "\n",
        "  # Warmup parameters (can be used with any scheduler)\n",
        "  warmup:\n",
        "    enabled: True\n",
        "    type: \"exponential\"  # Options: linear, exponential\n",
        "    epochs: 5\n",
        "    start_factor: 0.1\n",
        "    end_factor: 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Fl_9Vv117Q66"
      },
      "outputs": [],
      "source": [
        "with open('config_lm.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu56OILL7Q66"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XBrysj6-7Q66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                         Tokenizer Configuration (10k)                          \n",
            "--------------------------------------------------------------------------------\n",
            "Vocabulary size:     10000\n",
            "\n",
            "Special Tokens:\n",
            "PAD:              0\n",
            "UNK:              1\n",
            "MASK:             2\n",
            "SOS:              3\n",
            "EOS:              4\n",
            "BLANK:            5\n",
            "\n",
            "Validation Example:\n",
            "--------------------------------------------------------------------------------\n",
            "Input text:  [SOS]HI DEEP LEARNERS[EOS]\n",
            "Tokens:      ['[SOS]', 'H', 'I', 'ƒ†DEEP', 'ƒ†LEARN', 'ERS', '[EOS]']\n",
            "Token IDs:   [3, 14, 15, 1169, 2545, 214, 4]\n",
            "Decoded:     [SOS]HI DEEP LEARNERS[EOS]\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "Tokenizer = H4Tokenizer(\n",
        "    token_map  = config['tokenization']['token_map'],\n",
        "    token_type = config['tokenization']['token_type']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-vsGdfu7Q66"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OCR3fGoL7Q66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading transcripts for train partition...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/267178 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 267178/267178 [00:31<00:00, 8446.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading transcripts for val partition...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7031/7031 [00:00<00:00, 9102.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading transcripts for test partition...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7032/7032 [00:00<00:00, 9142.22it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1716"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset  = LMDataset(\n",
        "    partition  = config['data']['train_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "val_dataset    = LMDataset(\n",
        "    partition  = config['data']['val_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "test_dataset   = LMDataset(\n",
        "    partition  = config['data']['test_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf8Y_COP7Q66"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0GajQ0LX7Q66"
      },
      "outputs": [],
      "source": [
        "train_loader    = DataLoader(\n",
        "    dataset     = train_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = True,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = train_dataset.collate_fn\n",
        ")\n",
        "\n",
        "val_loader      = DataLoader(\n",
        "    dataset     = val_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = val_dataset.collate_fn\n",
        ")\n",
        "\n",
        "test_loader     = DataLoader(\n",
        "    dataset     = test_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = test_dataset.collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLKjKWJQ7Q67"
      },
      "source": [
        "### Dataloader Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xY40PhyN7Q67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "             Dataloader Verification              \n",
            "==================================================\n",
            "Dataloader Partition     : train\n",
            "--------------------------------------------------\n",
            "Number of Batches        : 261\n",
            "Batch Size               : 1024\n",
            "--------------------------------------------------\n",
            "Checking shapes of the data...                    \n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shifted Transcript Shape : [1024, 71]\n",
            "Golden Transcript Shape  : [1024, 71]\n",
            "Transcript Lengths Shape : [1024]\n",
            "--------------------------------------------------\n",
            "Max Transcript Length    : 105\n",
            "Avg. Chars per Token     : 4.62\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "verify_dataloader(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Shfm0w7E7Q67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "             Dataloader Verification              \n",
            "==================================================\n",
            "Dataloader Partition     : val\n",
            "--------------------------------------------------\n",
            "Number of Batches        : 7\n",
            "Batch Size               : 1024\n",
            "--------------------------------------------------\n",
            "Checking shapes of the data...                    \n",
            "\n",
            "Shifted Transcript Shape : [1024, 80]\n",
            "Golden Transcript Shape  : [1024, 80]\n",
            "Transcript Lengths Shape : [1024]\n",
            "--------------------------------------------------\n",
            "Max Transcript Length    : 87\n",
            "Avg. Chars per Token     : 4.61\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "verify_dataloader(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dlP3xkCg7Q67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "             Dataloader Verification              \n",
            "==================================================\n",
            "Dataloader Partition     : test\n",
            "--------------------------------------------------\n",
            "Number of Batches        : 7\n",
            "Batch Size               : 1024\n",
            "--------------------------------------------------\n",
            "Checking shapes of the data...                    \n",
            "\n",
            "Shifted Transcript Shape : [1024, 78]\n",
            "Golden Transcript Shape  : [1024, 78]\n",
            "Transcript Lengths Shape : [1024]\n",
            "--------------------------------------------------\n",
            "Max Transcript Length    : 86\n",
            "Avg. Chars per Token     : 4.61\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "verify_dataloader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrlXlZH7Q67"
      },
      "source": [
        "## Calculate Max Transcript Length\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIGxOLDU7Q67"
      },
      "source": [
        "Calculating the maximum transcript length across your dataset is a crucial step when working with certain transformer models.\n",
        "-  We'll use sinusoidal positional encodings that must be precomputed up to a fixed maximum length.\n",
        "- This maximum length is a hyperparameter that determines:\n",
        "  - How long of a sequence your model can process\n",
        "  - The size of your positional encoding matrix\n",
        "  - Memory requirements during training and inference\n",
        "- `Requirements`: For this assignment, ensure your positional encodings can accommodate at least the longest sequence in your dataset to prevent truncation. However, you can set this value higher if you anticipate using your language model to work with longer sequences in future tasks (hint: this might be useful for P2! üòâ)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iWAWHucJ7Q67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Global Max Transcript Length   : 105\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "max_transcript_length = max(train_dataset.text_max_len, val_dataset.text_max_len, test_dataset.text_max_len)\n",
        "print(\"=\"*50)\n",
        "print(f\"{'Global Max Transcript Length':<30} : {max_transcript_length}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot4OuRE27Q67"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qL2-8IbL7Q67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of shifted_transcripts :  torch.Size([1024, 79])\n",
            "Shape of golden_transcripts  :  torch.Size([1024, 79])\n",
            "Shape of transcript_lengths  :  torch.Size([1024])\n",
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "DecoderOnlyTransformer                        [1024, 79, 10000]         --\n",
            "‚îú‚îÄEmbedding: 1-1                              [1024, 79, 384]           3,840,000\n",
            "‚îú‚îÄPositionalEncoding: 1-2                     [1024, 79, 384]           --\n",
            "‚îú‚îÄDropout: 1-3                                [1024, 79, 384]           --\n",
            "‚îú‚îÄModuleList: 1-4                             --                        --\n",
            "‚îÇ    ‚îî‚îÄSelfAttentionDecoderLayer: 2-1         [1024, 79, 384]           --\n",
            "‚îÇ    ‚îÇ    ‚îî‚îÄSelfAttentionLayer: 3-1           [1024, 79, 384]           592,128\n",
            "‚îÇ    ‚îÇ    ‚îî‚îÄFeedForwardLayer: 3-2             [1024, 79, 384]           1,182,336\n",
            "‚îÇ    ‚îî‚îÄSelfAttentionDecoderLayer: 2-2         [1024, 79, 384]           --\n",
            "‚îÇ    ‚îÇ    ‚îî‚îÄSelfAttentionLayer: 3-3           [1024, 79, 384]           592,128\n",
            "‚îÇ    ‚îÇ    ‚îî‚îÄFeedForwardLayer: 3-4             [1024, 79, 384]           1,182,336\n",
            "‚îÇ    ‚îî‚îÄSelfAttentionDecoderLayer: 2-3         [1024, 79, 384]           --\n",
            "‚îÇ    ‚îÇ    ‚îî‚îÄSelfAttentionLayer: 3-5           [1024, 79, 384]           592,128\n",
            "‚îÇ    ‚îÇ    ‚îî‚îÄFeedForwardLayer: 3-6             [1024, 79, 384]           1,182,336\n",
            "‚îÇ    ‚îî‚îÄSelfAttentionDecoderLayer: 2-4         [1024, 79, 384]           --\n",
            "‚îÇ    ‚îÇ    ‚îî‚îÄSelfAttentionLayer: 3-7           [1024, 79, 384]           592,128\n",
            "‚îÇ    ‚îÇ    ‚îî‚îÄFeedForwardLayer: 3-8             [1024, 79, 384]           1,182,336\n",
            "‚îú‚îÄLayerNorm: 1-5                              [1024, 79, 384]           768\n",
            "‚îú‚îÄLinear: 1-6                                 [1024, 79, 10000]         3,850,000\n",
            "===============================================================================================\n",
            "Total params: 14,788,624\n",
            "Trainable params: 14,788,624\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 12.72\n",
            "===============================================================================================\n",
            "Input size (MB): 0.66\n",
            "Forward/backward pass size (MB): 13927.06\n",
            "Params size (MB): 49.69\n",
            "Estimated Total Size (MB): 13977.40\n",
            "===============================================================================================\n"
          ]
        }
      ],
      "source": [
        "model_config = config['model']\n",
        "model_config.update({\n",
        "    'max_len': max_transcript_length,\n",
        "    'num_classes': Tokenizer.vocab_size\n",
        "})\n",
        "model = DecoderOnlyTransformer(**model_config)\n",
        "\n",
        "# Get some inputs from the text loader\n",
        "for batch in train_loader:\n",
        "    shifted_transcripts, golden_transcripts, transcript_lengths = batch\n",
        "    print(\"Shape of shifted_transcripts : \", shifted_transcripts.shape)\n",
        "    print(\"Shape of golden_transcripts  : \", golden_transcripts.shape)\n",
        "    print(\"Shape of transcript_lengths  : \", transcript_lengths.shape)\n",
        "    break\n",
        "\n",
        "model_stats = summary(model, input_data=[shifted_transcripts, transcript_lengths])\n",
        "print(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH973f3x7Q67"
      },
      "source": [
        "## Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oz7os7UA7Q68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzhulenghan8211\u001b[0m (\u001b[33mzhulenghan8211-carnegie-mellon-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key=\"f83d7e9581d63eb876ad17665cf7c5c03d563770\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQAemeOM7Q68"
      },
      "source": [
        "## Trainer\n",
        "\n",
        "Every time you run the trainer, it will create a new directory in the `expts` folder with the following structure:\n",
        "```\n",
        "expts/\n",
        "    ‚îî‚îÄ‚îÄ {run_name}/\n",
        "        ‚îú‚îÄ‚îÄ config.yaml\n",
        "        ‚îú‚îÄ‚îÄ model_arch.txt\n",
        "        ‚îú‚îÄ‚îÄ checkpoints/\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ checkpoint-best-metric-model.pth\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint-last-epoch-model.pth\n",
        "        ‚îú‚îÄ‚îÄ attn/\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ {attention visualizations}\n",
        "        ‚îî‚îÄ‚îÄ text/\n",
        "            ‚îî‚îÄ‚îÄ {generated text outputs}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UcvGSnWi7Q68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "435a6a006e614e61b6dfc12aed95bb60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0111121578892279, max=1.0))‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/root/autodl-tmp/IDL-HW4/wandb/run-20250413_085118-r7j1nnyo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1/runs/r7j1nnyo' target=\"_blank\">lm-384/1536</a></strong> to <a href='https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1' target=\"_blank\">https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1/runs/r7j1nnyo' target=\"_blank\">https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1/runs/r7j1nnyo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = LMTrainer(\n",
        "    model=model,\n",
        "    tokenizer=Tokenizer,\n",
        "    config=config,\n",
        "    run_name=\"lm-384/1536\",\n",
        "    config_file=\"config_lm.yaml\",\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJREaFhqiPrT"
      },
      "source": [
        "### Setup Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GkljGtIPkATt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîß Configuring Optimizer:\n",
            "‚îú‚îÄ‚îÄ Type: ADAMW\n",
            "‚îú‚îÄ‚îÄ Base LR: 0.0005\n",
            "‚îú‚îÄ‚îÄ Weight Decay: 0.0001\n",
            "‚îú‚îÄ‚îÄ Parameter Groups:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ Group: self_attn\n",
            "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LR: 0.0001\n",
            "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Patterns: []\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ Group: ffn\n",
            "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LR: 0.0001\n",
            "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Patterns: []\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ Default Group (unmatched parameters)\n",
            "‚îî‚îÄ‚îÄ AdamW Specific:\n",
            "    ‚îú‚îÄ‚îÄ Betas: [0.9, 0.999]\n",
            "    ‚îú‚îÄ‚îÄ Epsilon: 1e-08\n",
            "    ‚îî‚îÄ‚îÄ AMSGrad: False\n"
          ]
        }
      ],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating a test scheduler and plotting the learning rate schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "inatJGBVi3II"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìà Configuring Learning Rate Scheduler:\n",
            "‚îú‚îÄ‚îÄ Type: COSINE\n",
            "‚îú‚îÄ‚îÄ Cosine Annealing Settings:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ T_max: 55 epochs (14355 steps)\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ Min LR: 1e-08\n",
            "‚îú‚îÄ‚îÄ Warmup Settings:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ Duration: 5 epochs (1305 steps)\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ Start Factor: 0.1\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ End Factor: 1.0\n",
            "Warning: Only showing 5 out of 52 parameter groups for clarity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/miniconda3/envs/hw4/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")\n",
        "\n",
        "plot_lr_schedule(\n",
        "    scheduler=test_scheduler,\n",
        "    num_epochs=config['training']['epochs'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yXrwTbqdiPE_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìà Configuring Learning Rate Scheduler:\n",
            "‚îú‚îÄ‚îÄ Type: COSINE\n",
            "‚îú‚îÄ‚îÄ Cosine Annealing Settings:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ T_max: 55 epochs (14355 steps)\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ Min LR: 1e-08\n",
            "‚îú‚îÄ‚îÄ Warmup Settings:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ Duration: 5 epochs (1305 steps)\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ Start Factor: 0.1\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ End Factor: 1.0\n"
          ]
        }
      ],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XI0dHJB7Q68"
      },
      "source": [
        "# Train\n",
        "- Set your epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nugAKoOw7Q68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 0):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.6298\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 7.5239\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 5.1031\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 1851.7010\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.5637\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 7.2152\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 4.7766\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 1359.9326\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 1):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.5647\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 7.2231\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 4.7812\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 1370.7615\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.5630\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 7.2119\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 4.7731\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 1355.4500\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 2):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.5555\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 7.1809\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 4.7377\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 1314.0436\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.5180\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 7.0045\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 4.5633\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 1101.5286\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000320\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 3):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.5032\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.9394\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 4.4962\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 1032.1465\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.4692\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.7789\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 4.3456\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 879.0737\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "[Training LM]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 260/261 [01:12<00:00,  3.37it/s, acc_step=1/1, ce_loss_token=6.7465, perplexity_token=851.1133]/root/miniconda3/envs/hw4/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 4):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.4613\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.7460\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 4.3117\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 850.6321\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.4246\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.5735\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 4.1564\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 715.8554\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 5):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.4264\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.5848\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 4.1638\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 724.0033\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.4029\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.4733\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 4.0671\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 647.6346\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 6):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.4049\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.4853\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 4.0750\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 655.4666\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.3715\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.3284\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.9414\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 560.2791\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 7):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3905\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.4189\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 4.0168\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 613.3515\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.3561\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.2570\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.8808\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 521.6447\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 8):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3659\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.3054\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.9192\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 547.5203\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.3360\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.1647\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.8040\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 475.6544\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 9):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3453\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.2104\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.8394\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 497.8864\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.3163\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.0736\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.7296\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 434.2301\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 10):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3446\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.2069\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.8365\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 496.1393\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.3145\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.0651\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.7228\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 430.5662\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 11):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3271\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.1261\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.7699\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 457.6429\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.3069\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 6.0301\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.6947\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 415.7760\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 12):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3259\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.1208\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.7656\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 455.2235\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2941\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.9709\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.6476\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 391.8767\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 13):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3022\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.0114\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.6774\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 408.0422\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2876\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.9411\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.6241\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 380.3578\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 14):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3017\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.0090\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.6755\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 407.0727\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2799\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.9055\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.5962\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 367.0607\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 15):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.3048\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 6.0234\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.6870\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 412.9740\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2751\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.8837\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.5792\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 359.1284\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 16):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2867\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.9397\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.6207\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 379.8063\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2572\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.8008\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.5155\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 330.5739\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 17):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2794\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.9059\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.5943\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 367.2018\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2552\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.7915\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.5084\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 327.4982\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 18):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2682\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.8542\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.5543\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 348.7114\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2472\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.7547\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.4806\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 315.6816\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 19):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2790\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.9044\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.5932\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 366.6583\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2427\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.7341\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.4650\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 309.2296\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 20):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2527\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.7829\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.4998\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 324.6926\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2336\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.6922\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.4337\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 296.5457\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 21):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2553\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.7948\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.5089\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 328.5880\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2289\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.6705\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.4176\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 290.1867\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 22):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2461\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.7525\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.4768\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 314.9692\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2271\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.6618\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.4112\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 287.6750\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 23):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2463\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.7532\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.4774\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 315.2118\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2252\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.6533\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.4049\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 285.2404\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 24):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2384\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.7167\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.4500\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 303.8962\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2169\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.6149\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3767\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 274.4788\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 25):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2325\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.6897\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.4299\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 295.8045\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2136\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5995\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3655\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 270.3035\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 26):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2277\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.6676\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.4135\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 289.3499\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2142\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.6026\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3677\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 271.1170\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 27):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2252\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.6557\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.4047\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 285.9296\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2098\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5823\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3529\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 265.6910\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 28):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2147\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.6075\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3693\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 272.4634\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2049\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5593\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3363\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 259.6514\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 29):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2142\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.6050\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3675\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 271.7786\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2030\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5506\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3299\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 257.3879\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 30):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2104\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5874\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3547\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 267.0391\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2027\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5492\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3290\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 257.0420\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 31):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2105\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5878\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3550\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 267.1515\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.2003\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5384\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3212\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 254.2784\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 32):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2128\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5988\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3630\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 270.1136\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1961\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5188\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.3070\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 249.3232\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 33):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1979\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5297\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3130\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 252.0563\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1924\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5019\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2950\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 245.1568\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 34):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.2017\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5474\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3258\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 256.5800\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1922\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.5011\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2944\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 244.9700\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 35):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1960\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5213\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3070\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 249.9590\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1899\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4905\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2869\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 242.3842\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 36):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1979\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5298\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.3131\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 252.0912\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1875\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4793\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2789\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 239.6825\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 37):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1908\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4971\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2897\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 243.9924\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1868\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4759\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2765\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 238.8582\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 38):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1918\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5019\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2931\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 245.1485\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1866\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4750\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2758\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 238.6388\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 39):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1935\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.5096\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2987\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 247.0592\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1874\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4788\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2785\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 239.5490\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 40):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1845\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4679\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2690\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 236.9600\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1833\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4600\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2652\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 235.0913\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 41):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1860\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4751\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2741\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 238.6791\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1820\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4539\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2609\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 233.6707\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 42):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1833\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4625\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2651\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 235.6756\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1810\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4493\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2576\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 232.5899\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 43):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1860\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4747\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2738\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 238.5874\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1819\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4535\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2606\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 233.5810\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 44):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1800\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4474\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2545\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 232.1530\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1811\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4497\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2579\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 232.6857\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 45):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1780\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4382\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2480\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 230.0170\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1797\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4433\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2534\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 231.1964\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 46):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1787\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4414\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2502\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 230.7543\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1780\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4355\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2479\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 229.4159\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 47):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1792\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4433\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2516\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 231.2100\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1783\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4370\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2490\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 229.7493\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 48):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1756\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4267\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2400\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 227.4054\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1772\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4319\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2454\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 228.5725\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 49):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1766\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4317\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2434\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 228.5333\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1774\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4325\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2458\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 228.7150\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 50):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1740\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4194\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2348\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 225.7413\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1765\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4287\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2431\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 227.8559\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 51):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1786\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4406\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2497\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 230.5709\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1758\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4253\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2408\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 227.0886\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 52):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1769\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4329\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2443\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 228.8039\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1761\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4269\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2419\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 227.4381\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 53):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1745\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4220\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2366\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 226.3305\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1757\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4250\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2405\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 227.0142\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 54):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1758\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4278\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2407\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 227.6507\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1760\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4262\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2414\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 227.2907\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 55):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1759\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4284\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2411\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 227.7829\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1758\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4251\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2406\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 227.0403\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 56):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1726\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4129\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2303\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 224.2877\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1753\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4231\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2392\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 226.5825\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 57):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1707\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4041\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2241\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 222.3131\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1758\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4251\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2406\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 227.0390\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 58):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1714\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4074\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2264\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 223.0489\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1755\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4241\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2399\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 226.7995\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/261 [00:00<?, ?it/s]/root/autodl-tmp/IDL-HW4/hw4lib/trainers/lm_trainer.py:122: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "                                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "üìä Metrics (Epoch 59):\n",
            "‚îú‚îÄ‚îÄ TRAIN:\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_char: 1.1725\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ ce_loss_token: 5.4126\n",
            "‚îÇ   ‚îú‚îÄ‚îÄ perplexity_char: 3.2300\n",
            "‚îÇ   ‚îî‚îÄ‚îÄ perplexity_token: 224.2109\n",
            "‚îî‚îÄ‚îÄ VAL:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1755\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4241\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2399\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 226.8112\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000000\n"
          ]
        }
      ],
      "source": [
        "trainer.train(train_loader, val_loader, epochs=config['training']['epochs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j55r9gK_7Q68"
      },
      "source": [
        "# Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "72D0yzHr7Q68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Metrics (Epoch 60):\n",
            "‚îî‚îÄ‚îÄ TEST:\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_char: 1.1753\n",
            "    ‚îú‚îÄ‚îÄ ce_loss_token: 5.4174\n",
            "    ‚îú‚îÄ‚îÄ perplexity_char: 3.2391\n",
            "    ‚îî‚îÄ‚îÄ perplexity_token: 225.3022\n",
            "‚îî‚îÄ‚îÄ TRAINING:\n",
            "    ‚îî‚îÄ‚îÄ learning_rate: 0.000000\n",
            "Generating with greedy search...\n",
            "Generating with beam search...\n",
            "Could not generate results for beam: \n",
            "Generating with sampling...\n",
            "Could not generate results for sample: \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/ce_loss_char</td><td>‚ñÅ</td></tr><tr><td>test/ce_loss_token</td><td>‚ñÅ</td></tr><tr><td>test/perplexity_char</td><td>‚ñÅ</td></tr><tr><td>test/perplexity_token</td><td>‚ñÅ</td></tr><tr><td>train/ce_loss_char</td><td>‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/ce_loss_token</td><td>‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/perplexity_char</td><td>‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/perplexity_token</td><td>‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/ce_loss_char</td><td>‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/ce_loss_token</td><td>‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/perplexity_char</td><td>‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val/perplexity_token</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>test/ce_loss_char</td><td>1.17529</td></tr><tr><td>test/ce_loss_token</td><td>5.41744</td></tr><tr><td>test/perplexity_char</td><td>3.23909</td></tr><tr><td>test/perplexity_token</td><td>225.30225</td></tr><tr><td>train/ce_loss_char</td><td>1.17249</td></tr><tr><td>train/ce_loss_token</td><td>5.41259</td></tr><tr><td>train/perplexity_char</td><td>3.23004</td></tr><tr><td>train/perplexity_token</td><td>224.21091</td></tr><tr><td>val/ce_loss_char</td><td>1.17555</td></tr><tr><td>val/ce_loss_token</td><td>5.42412</td></tr><tr><td>val/perplexity_char</td><td>3.23992</td></tr><tr><td>val/perplexity_token</td><td>226.81122</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lm-384/1536</strong> at: <a href='https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1/runs/r7j1nnyo' target=\"_blank\">https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1/runs/r7j1nnyo</a><br> View project at: <a href='https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1' target=\"_blank\">https://wandb.ai/zhulenghan8211-carnegie-mellon-university/HW4P1</a><br>Synced 5 W&B file(s), 121 media file(s), 0 artifact file(s) and 63 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250413_085118-r7j1nnyo/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_metrics, test_generation_results = trainer.evaluate(test_loader)\n",
        "# Cleanup\n",
        "trainer.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHw8LJp07Q68"
      },
      "source": [
        "# Submission\n",
        "To submit your assignment, you will need to create a `handin.tar` with the following directory structure:\n",
        "\n",
        "```\n",
        "handin/\n",
        "‚îú‚îÄ‚îÄ mytorch/                     # Your implemented modules\n",
        "‚îú‚îÄ‚îÄ test_metrics.json            # Results from evaluation\n",
        "‚îú‚îÄ‚îÄ test_generated_results.json  # Sample text generations\n",
        "‚îî‚îÄ‚îÄ model_arch.txt               # Model architecture summary\n",
        "```\n",
        "\n",
        "- Simply run the cell below once you are satisfied with your current state and this will create the `handin.tar` file.\n",
        "- After running the above cell, you should see the handin.tar file in the current directory\n",
        "- Upload the `handin.tar` file to the `HW4P1` assignment on Autolab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVSPaoOF7Q68"
      },
      "source": [
        "# Create temporary handin directory\n",
        "if os.path.exists('handin'):\n",
        "    shutil.rmtree('handin')\n",
        "os.makedirs('handin')\n",
        "\n",
        "# Copy mytorch directory\n",
        "shutil.copytree('mytorch', 'handin/mytorch')\n",
        "\n",
        "# Save final results\n",
        "with open('handin/test_metrics.json', 'w') as f:\n",
        "    json.dump(test_metrics, f, indent=4)\n",
        "\n",
        "with open('handin/test_generated_results.json', 'w') as f:\n",
        "    json.dump(test_generation_results['greedy'], f, indent=4)\n",
        "\n",
        "# Save model architecture\n",
        "with open('handin/model_arch.txt', 'w') as f:\n",
        "    f.write(str(model_stats))\n",
        "\n",
        "# Create tar file with all exclusions handled by filter\n",
        "with tarfile.open('handin.tar', 'w') as tar:\n",
        "    def filter_files(tarinfo):\n",
        "        # Skip unwanted files\n",
        "        if any(pattern in tarinfo.name for pattern in [\n",
        "            '.DS_Store',\n",
        "            '__pycache__',\n",
        "            '.pyc'\n",
        "        ]):\n",
        "            return None\n",
        "        return tarinfo\n",
        "\n",
        "    tar.add('handin', arcname='handin', filter=filter_files)\n",
        "\n",
        "# Cleanup\n",
        "shutil.rmtree('handin')\n",
        "\n",
        "print(\"Created handin.tar successfully!\")\n",
        "\n",
        "## After running the above cell, you should see the handin.tar file in the current directory\n",
        "!ls"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qQG51p6e7Q6x"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hw4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
